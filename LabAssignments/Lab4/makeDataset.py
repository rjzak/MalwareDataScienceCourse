#!/usr/bin/python3

import os
import sys
import pefile
from entropy import H

def featurizer(samplePath):
    try:
        pe = pefile.PE(samplePath)
    except Exception as e:
        print("Error parsing %s: %s." % (samplePath, str(e)))
        return None

    numberOfImportedDLLs = 0
    numberOfImportedFunctions = 0
    if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
        for entry in pe.DIRECTORY_ENTRY_IMPORT:
            numberOfImportedDLLs += 1
            for imp in entry.imports:
                numberOfImportedFunctions += 1

    entropy = H(open(samplePath, "rb").read())

    richHeaderValues = [0] * 10
    if pe.RICH_HEADER is not None:
        for headerIndex in range(min(10, len(pe.RICH_HEADER.values))):
            richHeaderValues[headerIndex] = pe.RICH_HEADER.values[headerIndex]
    #print(richHeaderValues)

    sectionSizes = [0] * 5
    for sectionIndex in range(min(5, pe.FILE_HEADER.NumberOfSections)):
        section = pe.sections[sectionIndex]
        sectionSizes[sectionIndex] = section.SizeOfRawData
    #print(sectionSizes)

    language_id = -1
    try:
        done = False
        for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:
            for resource_id in resource_type.directory.entries:
                for resource_lang in resource_id.directory.entries:
                    language_id = resource_lang.data.lang
                    done = True
                    break
                if done: break
            if done: break
    except:
        pass

    features = [
        pe.FILE_HEADER.Machine,  # Is the file 32-bit or 64-bit?
        pe.OPTIONAL_HEADER.Subsystem,  # Is the file a console app or graphical?
        pe.OPTIONAL_HEADER.AddressOfEntryPoint,  # Beginning point for execution
        pe.FILE_HEADER.NumberOfSections, # total number of sections, which could be more than five
        *sectionSizes, # section sizes for first five sections
        numberOfImportedDLLs,
        numberOfImportedFunctions,
        len(pe.get_warnings()),
        *richHeaderValues,
        int(pe.get_overlay_data_start_offset() is not None),  # Check for overlay, which is a sign of hiding something at the end of the file.
        language_id,
        entropy  # Entropy of the entire file
    ]
    return features

def makeDataset(goodwareDir, malwareDir, datasetPath):
    dataset = open(datasetPath, "w")
    for goodFile in os.listdir(goodwareDir):
        goodPath = os.path.join(goodwareDir, goodFile)
        features = featurizer(goodPath)
        if features is not None and len(features) > 0:
            dataset.write("-1") # LibSVM format: LABEL FEATINDEX1:value FEATINDEX2:value FEATINDEX9:value FEATINDEXN:value
            for index, feat in enumerate(features):
                if feat != 0:
                    dataset.write(" %d:%d" % (index, feat))
            dataset.write("\n")
    for badFile in os.listdir(malwareDir):
        badPath = os.path.join(malwareDir, badFile)
        features = featurizer(badPath)
        if features is not None and len(features) > 0:
            dataset.write("1")
            for index, feat in enumerate(features):
                if feat != 0:
                    dataset.write(" %d:%d" % (index, feat))
            dataset.write("\n")
    dataset.close()

if __name__ == '__main__':
    if len(sys.argv) != 4:
        print("Usage: %s <GoodwareDir> <MalwareDir> <DatasetFileSVM>" % sys.argv[0])
        sys.exit(1)

    goodwareDir = sys.argv[1]
    malwareDir = sys.argv[2]
    datasetFileOutput = sys.argv[3]

    for dirPath in (goodwareDir, malwareDir):
        if not os.path.isdir(dirPath):
            print("Error: %s is not a directory." % dirPath)
            sys.exit(1)

    makeDataset(goodwareDir, malwareDir, datasetFileOutput)