\documentclass{beamer}
\usepackage{graphicx}
\usepackage{listings} % Syntax highlighing
\usepackage{fancyvrb} % Inline verbatim
\usepackage{hyperref} % Hyperlinks
\hypersetup{pdfpagemode=FullScreen}
\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}

\usetheme{Boadilla}
\title{More Malware Models}
\author{UMBC Malware Data Science}
\date{Week 5: 24 February 2020}

\begin{document}

\begin{frame}{Recap}
    Last week, we discussed machine learning in general, and made Logistic Regression and Decision Tree models based on a few static features.
\end{frame}

\begin{frame}{Scientific Method}
    \begin{tikzpicture}
    % nodes
    \node (A) at (0, 0) {Hypothesis};
    \node (B) at (2.5, 0) {Experiment};
    \node (C) at (4.75, 0) {Results};
    \node (D) at (6.75, 0) {Analysis};
    
    % arrows
    \draw [->] (A) -- (B);
    \draw [->] (B) -- (C);
    \draw [->] (C) -- (D);
    \draw [->] (D.north) to [out=150,in=30] (A.north);
    \end{tikzpicture}
    \\ ~~ \\
    Our work with malware is the same:
    \begin{itemize}
        \item Results should be understandable by others.
        \item Results should be repeatable.
        \item Endgame's EMBER dataset \& the academic paper \textit{Variant: A Malware Similarity Testing Framework} offer common data for researchers to use to compare model accuracy.
        \item Here, we'll talk about algorithms and how to measure results to have a common language to discuss model performance.
        \begin{itemize}
            \item Otherwise: \includegraphics[scale=0.03]{Images/apple.jpg} $>$ \includegraphics[scale=0.04]{Images/orange.png}
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{ML Algorithms}
    There's more to machine learning that just neural networks, and often the simpler model is more useful.
    \begin{itemize}
        \item Linear \& Logistic Regression: Fit a line between groups of data, recall $y=mx + b$ from elementary school, but with a lot more variables.
        \item Decision Trees: Branches of decision-making, if this then that... until we can learn class A vs. B.
        \item Support Vector Machines (SVM): Similar to above, attempts to draw a line (hyperplane) between the classes.
        \item Artificial Neural Networks: Mimicking the connections of neurons in the brain to develop ratios which model the data
        \begin{itemize}
            \item Deep Neural Networks (``Deep Learning''): Networks on top of networks, this is where a lot of image recognition, language modeling, and many other domains build their advanced models.
        \end{itemize}
        \item And there's others...
    \end{itemize}
    \small
    Remember: ``\textit{All models are wrong, but some are useful}'' -- George E. Box
\end{frame}

\begin{frame}{Decision Tree}
    \includegraphics[scale=0.3]{Images/malware_decision_tree.png}
\end{frame}

\begin{frame}{Neural Network}
    \begin{columns}
        \column{0.55\textwidth} {
            \begin{itemize}
                \item Inputs are the features, outputs are malware or goodware in our case.
                \item The hidden nodes have initial random weights, which are multiplied by the input data, and the learning rate.
                \item During training, error information comes from the output to the hidden nodes to adjust it's internal weight value. This continues until the output is satisfactory.
                \item Due to randomness, the model will perform differently each time it's trained.
            \end{itemize}
        }
        \column{0.45\textwidth}{
            \includegraphics[scale=0.5]{Images/nn.png}
        }
   \end{columns}
\end{frame}

\begin{frame}{Measuring Results}
    When looking at the output of the model, there's more to consider than just accuracy.
    \begin{itemize}
        \item False Positives: Malware marked as benign
        \item False Negatives: Benign software marked malicious
        \item Recall $\frac{TP}{TP+FN}$: How much malware did we prevent from slipping by?
        \item Precision $\frac{TP}{TP+FP}$: How many of our malware predictions were actually malicious?
        \item F1 Score $2\frac{Recall * Precision}{Recall + Precision}$: Weighted average of above.
        \item ROC Curve (Receiver Operating Characteristics): Graph showing true positive rate vs. false positive rate.
        \item AUC (Area Under the [ROC] Curve): How good is the model at separating malware from goodware?
        \item Fortunately all of this already exists in \texttt{sklearn}!
    \end{itemize}
\end{frame}

\begin{frame}{ROC \& AUC}
    \includegraphics[scale=0.7]{Images/model_roc.png}
\end{frame}

\begin{frame}{Cross Validation}
    Another way to measure model performance is with $n$-fold cross validation. Instead of dividing the dataset into training and testing, the dataset is divided into several parts, with $n-1$ parts as training data, and one part as testing data. The resulting model with the best performance is the winning model, where the score type can be accuracy, AUC, F1, etc.
\end{frame}

\begin{frame}{Lab 5}
    For this Lab, we'll be using Endgame's EMBER dataset features with cross validation as implemented by sklearn to get the best model.
\end{frame}

\end{document}